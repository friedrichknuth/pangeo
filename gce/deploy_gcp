#!/usr/bin/env bash

# on GCP
# 0) get a GCP account if you don't already have one
# 1) create a project with a project name of pangeo and note the project id
# 2) switch to the pangeo project
# 3) in APIs and Services enable the Kubernetes Engine API for the pangeo project

# on local computer
# 1) install google cloud sdk (https://cloud.google.com/sdk/downloads)
# 2) install helm >=v2.8.2 (https://github.com/kubernetes/helm/blob/master/docs/install.md)
# 3) setup gcloud sdk
#    - gcloud components update
#    - gcloud components install kubectl
#    - gcloud config set container/new_scopes_behavior true
#    - gcloud auth login
# 4) modify secret-template.yaml file, replacing TOKEN with output from `openssl rand -hex 32`, and rename secret-config_gcp.yaml
# 5) modify the settings section of this file to match your settings and requirements
# 6) run this file on a not-windows machine

# settings
EMAIL='tjcrone@gmail.com'
PROJECTID='pangeo-198314'
ZONE='us-east4-a'
NUM_NODES=2
MIN_WORKER_NODES=0
MAX_WORKER_NODES=10

# create cluster on GCP
gcloud config set project $PROJECTID
gcloud container clusters create pangeo --num-nodes=$NUM_NODES --machine-type=n1-standard-2 --zone=$ZONE --no-enable-legacy-authorization --cluster-version=1.9.4-gke.1
gcloud container node-pools create worker-pool --zone=$ZONE --cluster=pangeo --machine-type=n1-standard-4 --preemptible --enable-autoscaling --num-nodes=$MIN_WORKER_NODES --max-nodes=$MAX_WORKER_NODES --min-nodes=$MIN_WORKER_NODES
gcloud container clusters get-credentials pangeo --zone=$ZONE --project $PROJECTID

# set up kubernetes
kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$EMAIL
kubectl create serviceaccount tiller --namespace=kube-system
kubectl create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
helm init --service-account tiller
#helm init --wait --service-account tiller
kubectl --namespace=kube-system patch deployment tiller-deploy --type=json --patch='[{"op": "add", "path": "/spec/template/spec/containers/0/command", "value": ["/tiller", "--listen=localhost:44134"]}]'

# get helm repositories
helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
helm repo update

# wait for tiller to come up
printf "\nWaiting for tiller to come up ..."
test=`helm status 2>&1 | cut -d' ' -f1-2`
while [[ $test != "Error: release" ]]; do
  test=`helm status 2>&1 | cut -d' ' -f1-2`
  sleep 1
done
printf " done.\n\n"

# install jupyterhub on the cluster
echo "Installing jupyterhub."
helm install jupyterhub/jupyterhub --version=v0.7-f58c7e7 --name=jupyter --namespace=jupyter -f secret-config.yaml -f jupyter-config_gcp.yaml

# create the kubernetesdask service account and role bindings
echo "Installing service account for dask-kubernetes."
kubectl create -f dask-kubernetes-serviceaccount.yaml

# wait for external ip address
printf "\nWaiting for external IP address ..."
IP=`kubectl --namespace=jupyter get svc proxy-public | grep -v "^NAME" | sed 's/  */ /g' | cut -d' ' -f4`
while [ $IP == "<pending>" ]; do
  IP=`kubectl --namespace=jupyter get svc proxy-public | grep -v "^NAME" | sed 's/  */ /g' | cut -d' ' -f4`
  sleep 1
done
printf " done.\n\n"
echo "Jupyterlab can now be accessed at $IP"
